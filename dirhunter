#!/bin/bash

# Tool for Web Directory Enumeration
# Developed by Cyberia

echo -e "\x1B[34m   ___  _     __             __         \x1B[0m"
echo -e "\x1B[34m  / _ \(_)___/ /  __ _____  / /____ ____\x1B[0m"
echo -e "\x1B[34m / // / / __/ _ \/ // / _ \/ __/ -_) __/\x1B[0m"
echo -e "\x1B[34m/____/_/_/ /_//_/\_,_/_//_/\__/\__/_/   \x1B[0m"
echo -e "\x1B[34m     Tool for Web Content Scanning.     \x1B[0m"
echo -e "\x1B[34m              by Cyberia.               \n\x1B[0m"

SITE=$1
ACCEPTED="200 403"
AGENTS=.useragents
DEFAULT=wordlists/common.txt
IP=`echo $SITE | awk -F[/:] '{print $4}'`

info(){

	echo -e "\x1B[34m[*]\x1B[0m Start time: \x1B[1;37m`date "+%F %X"`\x1B[0m" 									#Start time
	echo -e "\x1B[34m[*]\x1B[0m Hunting subdirectories: \x1B[1;37m$SITE\x1B[0m \x1B[34m[`dig +short $IP @resolver1.opendns.com | tail -1`]\x1B[0m"	#Website info
	echo -e "\x1B[34m[*]\x1B[0m Wordlist file: \x1B[1;37m$WD\x1B[0m \x1B[34m[`wc -l < $WD` lines]\x1B[0m\n"						#Wordlist info

}

check(){

	echo $ACCEPTED | grep -o -q $STATUS     		      #Checking whether the status code matches the $ACCEPTED variable
        if [ $? -eq 0 ]; then
		echo -e "\x1B[32m[+] \x1B[32m[$STATUS]\x1B[0m $SITE$word"
        fi

	echo $STATUS | grep -o -q ^3                                  #Checking for redirection
        if [ $? -eq 0 ]; then
		LOCATION=`curl -v -k $SITE$word |& grep -i location`  #Print "Location" header when found
                NEWURL=`echo $LOCATION | sed 's/^.*: //'`             #Grep the URL in "Location" header
                echo -e "\x1B[33m[*]\x1B[0m \x1B[33m[$STATUS]\x1B[0m \x1B[1;37m$SITE$word\x1B[0m redirects to: \x1B[1;37m$NEWURL\x1B[0m"
	fi

}

while :; do

	if [ -z $SITE ]; then
		echo -e "\x1B[34m[*]\x1B[0m \x1B[1;37mUsage: dirhunter <URL_Base> [<Wordlist_File>] [Options]\x1B[0m"
		echo -e "\x1B[34m[*]\x1B[0m Dirhunter is a Web Content Scanner. It searches for (existing/hidden) subdirectories on web servers, inspecting the HTTP response status codes.\n\n  -a, --agent           Customize your User-Agent.\n  -v, --verbose         Show also 404 [Not Found] pages.\n  -w, --wordlist        Specify your own wordlist.\n"
		break

	else	
		echo $SITE | egrep -q '^(http|https)://'  #Regex HTTP/HTTPS
		if [ $? -eq "1" ]; then
			echo -e "\x1B[31m[-]\x1B[0m Invalid URL format: \x1B[1;37m$SITE\x1B[0m\n\x1B[31m[-]\x1B[0m Use: “http://host/” or “https://host/”\x1B[0m\n\x1B[31m[-]\x1B[0m Exiting..."
			break
	        else
        	        echo $SITE | grep -q -E '/'$      #Force an ending "/" on URLs
                	if [ $? -eq 1 ]; then
                        	SITE="$SITE/"
	                fi
        	fi
	fi

	case $2 in
	--wordlist|-w)

		if [ -z $3 ]; then
			echo -e "\x1B[31m[-]\x1B[0m Missing operand.\x1B[0m\n\x1B[31m[-]\x1B[0m Exiting..."
                       	break
		
	       	elif [ -f $3 ]; then
			WD=$3
			info
		        for word in $(cat $WD); do
                		STATUS=`curl -o /dev/null -k -s -w "%{http_code}\n" "$SITE$word"`
		                check
		        done
		else
                        echo -e "\x1B[31m[-]\x1B[0m Wordlist file not found.\x1B[0m\n\x1B[31m[-]\x1B[0m Exiting..."			
			break
		fi
		shift

	;;
	--agent|-a)

		if [ -z "$3" ]; then
                        echo -e "\x1B[31m[-]\x1B[0m Missing operand.\x1B[0m\n\x1B[31m[-]\x1B[0m Exiting..."
                        break

		else
			cat $AGENTS | grep -o -q "$3"$
			if [ $? -eq 0 ]; then
				WD=$DEFAULT
				info
				for word in $(cat $WD); do
					STATUS=`curl -o /dev/null -A "$3" -k -s -w "%{http_code}\n" "$SITE$word"`
					check
				done
			else
				echo -e "\x1B[31m[-]\x1B[0m Unknown user-agent.\x1B[0m\n\x1B[31m[-]\x1B[0m Exiting..."
				break
			fi
		fi
		shift

	;;
	--verbose|-v)

		WD=$DEFAULT
       		info
		for word in $(cat $WD); do
			STATUS=`curl -o /dev/null -k -s -w "%{http_code}\n" "$SITE$word"`
			echo "$ACCEPTED" | grep -o -q "$STATUS"
        		if [ $? -eq 0 ]; then
                		echo -e "\x1B[32m[+]\x1B[0m \x1B[32m[$STATUS]\x1B[0m $SITE$word"
			fi

		        echo $STATUS | grep -o -q ^3
		        if [ $? -eq 0 ]; then
                		LOCATION=`curl -v -k $SITE$word |& grep -i location`  #Print "Location" header when found
		                NEWURL=`echo $LOCATION | sed 's/^.*: //'`             #Grep the URL in "Location" header
                		echo -e "\x1B[33m[*]\x1B[0m \x1B[33m[$STATUS]\x1B[0m \x1B[1;37m$SITE$word\x1B[0m redirects to: \x1B[1;37m$NEWURL\x1B[0m"
			else
                		echo -e "\x1B[31m[-]\x1B[0m \x1B[31m[$STATUS]\x1B[0m $SITE$word"
        		fi
		done
		shift	

	;;
        '')

		if [ -z $2 ] && [ -f $DEFAULT ]; then
			WD=$DEFAULT
			info
	        	for word in $(cat $WD); do
        	        	STATUS=`curl -o /dev/null -k -s -w "%{http_code}\n" "$SITE$word"`
				check
        		done
		else
                        echo -e "\x1B[31m[-]\x1B[0m Default wordlist not found, try passing a custom wordlist as a parameter.\n\x1B[31m[-]\x1B[0m Exiting..." 
        		break
		fi
		shift

	;;
	*)

		echo -e "\x1B[31m[-]\x1B[0m Invalid option.\n\x1B[31m[-]\x1B[0m Exiting..." 		
		break

	esac
	shift

done
